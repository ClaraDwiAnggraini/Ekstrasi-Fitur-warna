#import the libraries
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #Data Visualization 
import seaborn as sns  #Python library for Vidualization

data = pd.read_excel(r"C:\Users\asus\Documents\anacondaa\TA bismillah\dataset\klasifikasi 2\data hari 1.xlsx", engine = 'openpyxl')
data
data.head()
dataset = data.drop(['Pixel', 'Kategori'],axis=1)
dataset.head()
#total rows and colums in the dataset
dataset.shape

#Building the Model
#KMeans Algorithm to decide the optimum cluster number , KMeans++ using Elbow Mmethod
#to figure out K for KMeans, I will use ELBOW Method on KMEANS++ Calculation
from sklearn.cluster import KMeans
wcss=[]

#we always assume the max number of cluster would be 10
#you can judge the number of clusters by doing averaging
###Static code to get max no of clusters

for i in range(1,11):
    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=10)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

    #inertia_ is the formula used to segregate the data points into clusters
    

#Visualizing the ELBOW method to get the optimal value of K 
plt.plot(range(1,11), wcss)
plt.title('The Elbow Method')
plt.xlabel('no of clusters')
plt.ylabel('wcss')
plt.show()

#menyusun model
kmeansmodel = KMeans(n_clusters= 2, init='k-means++', random_state=0)
kmeans = kmeans.fit(dataset[['R_ave', 'G_ave', 'B_ave', 'L_ave', 'a_ave', 'b_ave', 'H_ave', 'S_ave', 'V_ave']])
y_kmeans= kmeansmodel.fit_predict(X)


#For unsupervised learning we use "fit_predict()" wherein for supervised learning we use "fit_tranform()"
#y_kmeans is the final model . Now how and where we will deploy this model in production is depends on what tool we are using.
#This use case is very common and it is used in BFS industry(credit card) and retail for customer segmenattion.
#Visualizing all the clusters 

plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')
plt.title('Hasil Cluster 1')
plt.xlabel('Data')
plt.ylabel('Hasil')
plt.legend()
plt.show()

dataset['clusters'] =y_kmeans
dataset.to_excel("1.xlsx")
